{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Francisco Teixeira Rocha Aragão 2021031726\n",
    "\n",
    "Nesse arquivo contem a implementação da solução para um problema de 'pos tagging', que é a tarefa de atribuir uma tag a cada palavra de uma sentença, em que no caso deste trabalho, envolve a atribuição de tags de classes gramáticais para frases em português.\n",
    "\n",
    "Os dados utilizados são do corpus MacMorpho, que contém textos em português com as respectivas tags de classes gramaticais. O corpus já está dividido em 3 partes: treino, validação e teste. É possível baixar o corpus no [link referenciado](http://nilc.icmc.usp.br/macmorpho/macmorpho-v3.tgz)\n",
    "\n",
    "Desse modo, o trabalho desenvolvido envolve a utilização de modelos para realizar a tarefa de pos tagging, com o desempenho sendo medido e retornando em cada caso testado. Vale destacar inicialmente que algumas estratégias foram testadas, porém não foram bem sucessidas, como o treinamento de muitas camadas do modelo BERT em português, ou a utilização de LLMs para a tarefa de pos tagging. A falta de sucesso deve-se a necessidade de maior poder de processamento, GPU e de memória para trabalhar com tarefas tão complexas e modelos tão grandes, o que não foi possível de ser feito localmente.\n",
    "\n",
    "Com isso, a estratégia adotada foi de utilizar modelos já especializados na tarefa de pós taggins (fine tuning). Assim, os modelos escolhidos foram treinandos utilizando o próprio dataset MacMorpho, além de terem como base modelos BERT treinados em língua portuguesa. Fazer o uso desses modelos foi de grande ajuda pois não foi necessário o treinamento, apenas carregar em memória e utilizar.\n",
    "\n",
    "Os resultados da utilização dos modelos estão descritos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francisco/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tp2/pos_tagging/env_py/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_and_print_general_accuracy(results, total_words):\n",
    "    correct_predictions = 0\n",
    "    for result in results:\n",
    "        if result['correct']:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_words\n",
    "    print(f'Acurácia geral: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_and_print_accuracy_and_len_by_tag(results):\n",
    "    correct_tags = {}\n",
    "    total_tags = {}\n",
    "\n",
    "    for result in results:\n",
    "        if result['tag'] not in total_tags:\n",
    "            total_tags[result['tag']] = 1\n",
    "        else:\n",
    "            total_tags[result['tag']] += 1\n",
    "        \n",
    "        if result['correct']:\n",
    "            if result['tag'] not in correct_tags:\n",
    "                correct_tags[result['tag']] = 1\n",
    "            else:\n",
    "                correct_tags[result['tag']] += 1\n",
    "\n",
    "    accuracy_tags = {}\n",
    "    for tag in total_tags:\n",
    "        try:\n",
    "            accuracy_tags[tag] = correct_tags[tag] / total_tags[tag]\n",
    "        except KeyError:\n",
    "            accuracy_tags[tag] = 0\n",
    "\n",
    "    couting_tags = {}\n",
    "    for tag, total in total_tags.items():\n",
    "        couting_tags[tag] = total\n",
    "\n",
    "    # print in descending order\n",
    "    for tag, accuracy in sorted(accuracy_tags.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f'TAG: {tag} - ACURÁCIA: {accuracy:.2f} - OCORRÊNCIAS: {couting_tags[tag]}')\n",
    "    \n",
    "    return total_tags, accuracy_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_and_print_precision_recall_f1_by_tag(results):\n",
    "    \n",
    "    # contando TRUE_POSITIVES, FALSE_POSITIVES e FALSE_NEGATIVES para cada tag\n",
    "    # FALSE_POSITIVE: previu como essa tag, mas não era\n",
    "    # FALSE_NEGATIVE: era essa tag, mas previu como outra\n",
    "    # TRUE_POSITIVE: previu como essa tag e era essa tag\n",
    "    true_positives = defaultdict(int)\n",
    "    false_positives = defaultdict(int)\n",
    "    false_negatives = defaultdict(int)\n",
    "\n",
    "    for result in results:\n",
    "        predicted_tag = result['prediction']\n",
    "        expected_tag = result['tag']\n",
    "        correct_prediction = result[\"correct\"]\n",
    "        \n",
    "        if correct_prediction:  # True Positive\n",
    "            true_positives[predicted_tag] += 1\n",
    "        else:\n",
    "            # False Positive\n",
    "            false_positives[predicted_tag] += 1\n",
    "            # False Negative\n",
    "            false_negatives[expected_tag] += 1\n",
    "\n",
    "    # calculando precisão, recall e f1-score para cada tag\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    f1_score = {}\n",
    "\n",
    "    for tag in set(true_positives.keys()).union(false_positives.keys()).union(false_negatives.keys()):\n",
    "        tp = true_positives[tag]\n",
    "        fp = false_positives[tag]\n",
    "        fn = false_negatives[tag]\n",
    "        \n",
    "        # Precisão: TP / (TP + FP)\n",
    "        precision[tag] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        \n",
    "        # recall: TP / (TP + FN)\n",
    "        recall[tag] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        \n",
    "        # f1-Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "        if precision[tag] + recall[tag] > 0:\n",
    "            f1_score[tag] = 2 * (precision[tag] * recall[tag]) / (precision[tag] + recall[tag])\n",
    "        else:\n",
    "            f1_score[tag] = 0\n",
    "\n",
    "    for tag in sorted(f1_score.keys(), key=lambda t: f1_score[t], reverse=True):\n",
    "        print(f'TAG {tag} - Precision {precision[tag]:.2f} - Recall {recall[tag]:.2f} - F1 {f1_score[tag]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro modelo: Fine-tuning do modelo BioBERTpt(all) com corpus MacMorpho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/home/francisco/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tp2/pos_tagging/env_py/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pucpr-br/postagger-bio-portuguese\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"pucpr-br/postagger-bio-portuguese\")\n",
    "\n",
    "nlp_token_class = pipeline('ner', model=model, tokenizer=tokenizer, grouped_entities=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/macmorpho-train.txt', 'r') as file:\n",
    "    # store file content in a list\n",
    "    lines = file.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jersei_N atinge_V média_N de_PREP Cr$_CUR 1,4_NUM milhão_N na_PREP+ART venda_N da_PREP+ART Pinhal_NPROP em_PREP São_NPROP Paulo_NPROP ._PU\\n', 'Programe_V sua_PROADJ viagem_N à_PREP+ART Exposição_NPROP Nacional_NPROP do_NPROP Zebu_NPROP ,_PU que_PRO-KS começa_V dia_N 25_N ._PU\\n', 'Safra_N recorde_ADJ e_KC disponibilidade_N de_PREP crédito_N ativam_V vendas_N de_PREP máquinas_N agrícolas_ADJ ._PU\\n', 'A_ART desertificação_N tornou_V crítica_ADJ a_ART produtividade_N de_PREP 52_NUM mil_NUM km²_N na_PREP+ART região_N ._PU\\n']\n"
     ]
    }
   ],
   "source": [
    "print(lines[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizando os dados, separando as palavras das tags\n",
    "words = []\n",
    "tags = []\n",
    "for line in lines[0:int(len(lines)*0.7)]:\n",
    "    # separate each word\n",
    "    words_tags = line.split()\n",
    "    for word_tag in words_tags:\n",
    "        # separate the word from the tag\n",
    "        word, tag = word_tag.split('_')\n",
    "        words.append(word)\n",
    "        tags.append(tag.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Salto', 'sete', 'O', 'grande']\n",
      "['N', 'ADJ', 'ART', 'ADJ']\n"
     ]
    }
   ],
   "source": [
    "print(words[0:4])\n",
    "print(tags[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizando a inferência das tags\n",
    "total_words = len(words)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 518670/518670 [2:17:52<00:00, 62.70it/s]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "for word, tag in tqdm(zip(words, tags), total=total_words, desc=\"Processing words\"):\n",
    "    prediction = nlp_token_class(word)\n",
    "    result = {\n",
    "        'word': word,\n",
    "        'tag': tag,\n",
    "        'prediction': prediction[0]['entity_group']\n",
    "    }\n",
    "    if prediction[0]['entity_group'] == tag:\n",
    "        result['correct'] = True\n",
    "    else:\n",
    "        result['correct'] = False\n",
    "    \n",
    "    results.append(result)\n",
    "\n",
    "# salvando resultados em um arquivo para análise posterior\n",
    "\n",
    "with open('results/results_postagger-bio-portuguese.json', 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrino o arquivo gerado\n",
    "with open('results/results_postagger-bio-portuguese.json', 'r') as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia geral: 0.68\n"
     ]
    }
   ],
   "source": [
    "# calculando acurácia do modelo\n",
    "measure_and_print_general_accuracy(results, total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG: PREP+PROPESS - ACURÁCIA: 0.98 - OCORRÊNCIAS: 225\n",
      "TAG: N - ACURÁCIA: 0.96 - OCORRÊNCIAS: 114296\n",
      "TAG: KC - ACURÁCIA: 0.96 - OCORRÊNCIAS: 11980\n",
      "TAG: PU - ACURÁCIA: 0.95 - OCORRÊNCIAS: 73027\n",
      "TAG: V - ACURÁCIA: 0.92 - OCORRÊNCIAS: 54271\n",
      "TAG: ADV - ACURÁCIA: 0.92 - OCORRÊNCIAS: 11689\n",
      "TAG: PREP+ART - ACURÁCIA: 0.89 - OCORRÊNCIAS: 33970\n",
      "TAG: PREP+ADV - ACURÁCIA: 0.88 - OCORRÊNCIAS: 25\n",
      "TAG: PCP - ACURÁCIA: 0.79 - OCORRÊNCIAS: 11310\n",
      "TAG: PROSUB - ACURÁCIA: 0.59 - OCORRÊNCIAS: 2745\n",
      "TAG: PDEN - ACURÁCIA: 0.57 - OCORRÊNCIAS: 2933\n",
      "TAG: NPROP - ACURÁCIA: 0.50 - OCORRÊNCIAS: 50000\n",
      "TAG: PROPESS - ACURÁCIA: 0.50 - OCORRÊNCIAS: 4728\n",
      "TAG: PREP+PROSUB - ACURÁCIA: 0.45 - OCORRÊNCIAS: 317\n",
      "TAG: PROADJ - ACURÁCIA: 0.43 - OCORRÊNCIAS: 7102\n",
      "TAG: PREP+PROADJ - ACURÁCIA: 0.37 - OCORRÊNCIAS: 889\n",
      "TAG: ADJ - ACURÁCIA: 0.36 - OCORRÊNCIAS: 22321\n",
      "TAG: IN - ACURÁCIA: 0.25 - OCORRÊNCIAS: 75\n",
      "TAG: ART - ACURÁCIA: 0.22 - OCORRÊNCIAS: 39167\n",
      "TAG: PREP - ACURÁCIA: 0.22 - OCORRÊNCIAS: 52318\n",
      "TAG: KS - ACURÁCIA: 0.09 - OCORRÊNCIAS: 6440\n",
      "TAG: NUM - ACURÁCIA: 0.07 - OCORRÊNCIAS: 11059\n",
      "TAG: CUR - ACURÁCIA: 0.00 - OCORRÊNCIAS: 1887\n",
      "TAG: PRO-KS - ACURÁCIA: 0.00 - OCORRÊNCIAS: 5330\n",
      "TAG: ADV-KS - ACURÁCIA: 0.00 - OCORRÊNCIAS: 478\n",
      "TAG: PREP+PRO-KS - ACURÁCIA: 0.00 - OCORRÊNCIAS: 88\n"
     ]
    }
   ],
   "source": [
    "# observando resultados mais detalhados\n",
    "\n",
    "# agora é calculado a acurácia para cada tag\n",
    "total_tags, accuracy_tags = measure_and_print_accuracy_and_len_by_tag(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG PREP+PROPESS - Precision 1.00 - Recall 0.98 - F1 0.99\n",
      "TAG KC - Precision 0.97 - Recall 0.96 - F1 0.97\n",
      "TAG PU - Precision 0.96 - Recall 0.95 - F1 0.95\n",
      "TAG V - Precision 0.98 - Recall 0.92 - F1 0.95\n",
      "TAG PREP+ART - Precision 0.94 - Recall 0.89 - F1 0.91\n",
      "TAG PCP - Precision 0.95 - Recall 0.79 - F1 0.86\n",
      "TAG PREP+ADV - Precision 0.76 - Recall 0.88 - F1 0.81\n",
      "TAG N - Precision 0.67 - Recall 0.96 - F1 0.79\n",
      "TAG ADV - Precision 0.63 - Recall 0.92 - F1 0.75\n",
      "TAG PDEN - Precision 0.92 - Recall 0.57 - F1 0.71\n",
      "TAG NPROP - Precision 0.91 - Recall 0.50 - F1 0.64\n",
      "TAG PROPESS - Precision 0.75 - Recall 0.50 - F1 0.60\n",
      "TAG PROADJ - Precision 0.90 - Recall 0.43 - F1 0.58\n",
      "TAG PREP+PROADJ - Precision 1.00 - Recall 0.37 - F1 0.54\n",
      "TAG ADJ - Precision 0.92 - Recall 0.36 - F1 0.52\n",
      "TAG ART - Precision 0.96 - Recall 0.22 - F1 0.36\n",
      "TAG PREP - Precision 0.94 - Recall 0.22 - F1 0.35\n",
      "TAG PREP+PROSUB - Precision 0.18 - Recall 0.45 - F1 0.26\n",
      "TAG IN - Precision 0.12 - Recall 0.25 - F1 0.16\n",
      "TAG PROSUB - Precision 0.08 - Recall 0.59 - F1 0.15\n",
      "TAG KS - Precision 0.28 - Recall 0.09 - F1 0.14\n",
      "TAG NUM - Precision 0.82 - Recall 0.07 - F1 0.13\n",
      "TAG ADV-KS - Precision 0.00 - Recall 0.00 - F1 0.00\n",
      "TAG CUR - Precision 0.00 - Recall 0.00 - F1 0.00\n",
      "TAG <pad> - Precision 0.00 - Recall 0.00 - F1 0.00\n",
      "TAG PREP+PRO-KS - Precision 0.00 - Recall 0.00 - F1 0.00\n",
      "TAG PRO-KS - Precision 0.00 - Recall 0.00 - F1 0.00\n"
     ]
    }
   ],
   "source": [
    "measure_and_print_precision_recall_f1_by_tag(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo modelo: Fine-tuning do modelo BERTimbau com corpus MacMorpho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# carregando o modelo\n",
    "pipe = pipeline(\"token-classification\", model=\"lisaterumi/postagger-portuguese\", tokenizer=\"lisaterumi/postagger-portuguese\", aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo dados de entrada novamente e separado melhor o arquivo\n",
    "with open('data/macmorpho-train.txt', 'r') as file:\n",
    "    # store file content in a list\n",
    "    lines = file.readlines()\n",
    "\n",
    "dataT = []\n",
    "\n",
    "for line in lines[0:int(len(lines)*0.7)]:\n",
    "    words_tags = line.split()\n",
    "    for word_tag in words_tags:\n",
    "        word, tag = word_tag.split('_')\n",
    "        dataT.append((word, tag.strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jersei', 'N'),\n",
       " ('atinge', 'V'),\n",
       " ('média', 'N'),\n",
       " ('de', 'PREP'),\n",
       " ('Cr$', 'CUR')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataT[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ',\n",
       " 'ADV',\n",
       " 'ADV-KS',\n",
       " 'ART',\n",
       " 'CUR',\n",
       " 'IN',\n",
       " 'KC',\n",
       " 'KS',\n",
       " 'N',\n",
       " 'NPROP',\n",
       " 'NUM',\n",
       " 'PCP',\n",
       " 'PDEN',\n",
       " 'PREP',\n",
       " 'PREP+ADV',\n",
       " 'PREP+ART',\n",
       " 'PREP+PRO-KS',\n",
       " 'PREP+PROADJ',\n",
       " 'PREP+PROPESS',\n",
       " 'PREP+PROSUB',\n",
       " 'PRO-KS',\n",
       " 'PROADJ',\n",
       " 'PROPESS',\n",
       " 'PROSUB',\n",
       " 'PU',\n",
       " 'V'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pegando todas as tags\n",
    "tags = set([tag for _, tag in dataT])\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 387877/387877 [1:34:09<00:00, 68.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# raelizando predição das tags\n",
    "results = []\n",
    "\n",
    "for word, expected_tag in tqdm(dataT, desc=\"Processing words\"):\n",
    "    prediction = pipe(word)\n",
    "    \n",
    "    # pegando a tag prevista\n",
    "    predicted_tag = prediction[0]['entity_group']\n",
    "    \n",
    "    result_data = {\n",
    "        'word': word,\n",
    "        'tag': expected_tag,\n",
    "        'prediction': predicted_tag,\n",
    "        'correct': predicted_tag == expected_tag,\n",
    "    }\n",
    "    \n",
    "    # Append result to the results list\n",
    "    results.append(result_data)\n",
    "        \n",
    "# salvando resultados em um arquivo json\n",
    "with open('results/results_postagger-portuguese.json', 'w') as file:\n",
    "    json.dump(results, file, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrindo arquivo para analise dos resultados -> acuracia geral\n",
    "\n",
    "with open('results/results_postagger-portuguese.json', 'r') as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia geral: 0.74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_words = len(results)\n",
    "\n",
    "measure_and_print_general_accuracy(results, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG: PU - ACURÁCIA: 1.00 - OCORRÊNCIAS: 54718\n",
      "TAG: PREP+PROPESS - ACURÁCIA: 0.98 - OCORRÊNCIAS: 164\n",
      "TAG: N - ACURÁCIA: 0.97 - OCORRÊNCIAS: 86505\n",
      "TAG: KC - ACURÁCIA: 0.96 - OCORRÊNCIAS: 9046\n",
      "TAG: ADV - ACURÁCIA: 0.92 - OCORRÊNCIAS: 8004\n",
      "TAG: V - ACURÁCIA: 0.92 - OCORRÊNCIAS: 40086\n",
      "TAG: PREP+ADV - ACURÁCIA: 0.89 - OCORRÊNCIAS: 19\n",
      "TAG: PROSUB - ACURÁCIA: 0.88 - OCORRÊNCIAS: 1887\n",
      "TAG: PREP - ACURÁCIA: 0.85 - OCORRÊNCIAS: 39865\n",
      "TAG: PCP - ACURÁCIA: 0.82 - OCORRÊNCIAS: 8743\n",
      "TAG: PROPESS - ACURÁCIA: 0.79 - OCORRÊNCIAS: 3366\n",
      "TAG: PREP+ART - ACURÁCIA: 0.75 - OCORRÊNCIAS: 24920\n",
      "TAG: PDEN - ACURÁCIA: 0.56 - OCORRÊNCIAS: 2116\n",
      "TAG: ADJ - ACURÁCIA: 0.50 - OCORRÊNCIAS: 16352\n",
      "TAG: NPROP - ACURÁCIA: 0.49 - OCORRÊNCIAS: 37713\n",
      "TAG: PREP+PROADJ - ACURÁCIA: 0.47 - OCORRÊNCIAS: 647\n",
      "TAG: PREP+PROSUB - ACURÁCIA: 0.41 - OCORRÊNCIAS: 217\n",
      "TAG: IN - ACURÁCIA: 0.40 - OCORRÊNCIAS: 20\n",
      "TAG: NUM - ACURÁCIA: 0.12 - OCORRÊNCIAS: 8412\n",
      "TAG: ART - ACURÁCIA: 0.08 - OCORRÊNCIAS: 29287\n",
      "TAG: PROADJ - ACURÁCIA: 0.05 - OCORRÊNCIAS: 5205\n",
      "TAG: KS - ACURÁCIA: 0.00 - OCORRÊNCIAS: 4719\n",
      "TAG: CUR - ACURÁCIA: 0.00 - OCORRÊNCIAS: 1485\n",
      "TAG: PRO-KS - ACURÁCIA: 0.00 - OCORRÊNCIAS: 3961\n",
      "TAG: ADV-KS - ACURÁCIA: 0.00 - OCORRÊNCIAS: 354\n",
      "TAG: PREP+PRO-KS - ACURÁCIA: 0.00 - OCORRÊNCIAS: 66\n"
     ]
    }
   ],
   "source": [
    "total_tags, accuracy_tags = measure_and_print_accuracy_and_len_by_tag(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG PREP+PROPESS - Precision 1.00 - Recall 0.98 - F1 0.99\n",
      "TAG KC - Precision 0.96 - Recall 0.96 - F1 0.96\n",
      "TAG V - Precision 0.98 - Recall 0.92 - F1 0.95\n",
      "TAG PREP - Precision 0.93 - Recall 0.85 - F1 0.89\n",
      "TAG PCP - Precision 0.95 - Recall 0.82 - F1 0.88\n",
      "TAG PREP+ADV - Precision 0.77 - Recall 0.89 - F1 0.83\n",
      "TAG PU - Precision 0.71 - Recall 1.00 - F1 0.83\n",
      "TAG PREP+ART - Precision 0.92 - Recall 0.75 - F1 0.83\n",
      "TAG N - Precision 0.66 - Recall 0.97 - F1 0.79\n",
      "TAG ADV - Precision 0.67 - Recall 0.92 - F1 0.77\n",
      "TAG PROPESS - Precision 0.72 - Recall 0.79 - F1 0.75\n",
      "TAG PDEN - Precision 0.93 - Recall 0.56 - F1 0.70\n",
      "TAG NPROP - Precision 0.99 - Recall 0.49 - F1 0.65\n",
      "TAG ADJ - Precision 0.88 - Recall 0.50 - F1 0.64\n",
      "TAG PREP+PROADJ - Precision 0.96 - Recall 0.47 - F1 0.63\n",
      "TAG PREP+PROSUB - Precision 0.30 - Recall 0.41 - F1 0.34\n",
      "TAG NUM - Precision 0.89 - Recall 0.12 - F1 0.21\n",
      "TAG IN - Precision 0.14 - Recall 0.40 - F1 0.21\n",
      "TAG ART - Precision 0.93 - Recall 0.08 - F1 0.16\n",
      "TAG PROSUB - Precision 0.07 - Recall 0.88 - F1 0.13\n",
      "TAG PROADJ - Precision 0.86 - Recall 0.05 - F1 0.10\n",
      "TAG KS - Precision 0.95 - Recall 0.00 - F1 0.01\n",
      "TAG ADV-KS - Precision 0.00 - Recall 0.00 - F1 0.00\n",
      "TAG CUR - Precision 0.00 - Recall 0.00 - F1 0.00\n",
      "TAG <pad> - Precision 0.00 - Recall 0.00 - F1 0.00\n",
      "TAG PREP+PRO-KS - Precision 0.00 - Recall 0.00 - F1 0.00\n",
      "TAG PRO-KS - Precision 0.00 - Recall 0.00 - F1 0.00\n"
     ]
    }
   ],
   "source": [
    "measure_and_print_precision_recall_f1_by_tag(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
